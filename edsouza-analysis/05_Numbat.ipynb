{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda activate numbat\n",
    "ln -s \"/home/ubuntu/InstallTemp/numbat/Eagle_v2.4.1/eagle\" \"${CONDA_PREFIX}/bin/eagle\"  # IMPORTANT!\n",
    "\n",
    "\n",
    "numbat_out=\"/home/ubuntu/data/cxcr4-pdac/numbat\"\n",
    "numbat_input=\"${numbat_out}/input\"\n",
    "mkdir -p ${numbat_input}\n",
    "NUMBAT=\"/home/ubuntu/InstallTemp/numbat\"\n",
    "cores=$(nproc)\n",
    "\n",
    "\n",
    "\n",
    "# The for loops in this script are wonky because I chose to use 4 separate machines\n",
    "# to process samples in parallel. Feel free to modify the iteration scheme\n",
    "# as needed if you want to run this yourself.\n",
    "for i in {22..40..4};  # for i in {XYZ..40..4}. Replace XYZ with 19, 20, 21, 22 on 4 diff instances running in parallel\n",
    "do\n",
    "    sample=\"GM${i}\"\n",
    "\n",
    "    if [[  $i -ne 25 ]] \n",
    "    then\n",
    "        bam_local=\"${numbat_input}/${sample}_possorted_genome.bam\"\n",
    "        barcodefile=\"${numbat_input}/${sample}_barcodes.tsv\"\n",
    "        outdir=\"${numbat_out}/${sample}\"\n",
    "        mkdir -p ${outdir}\n",
    "        logfile=\"${outdir}/${sample}_log.txt\"\n",
    "        pileup_donefile=\"${outdir}/finished.checkpoint\"\n",
    "\n",
    "        if [ ! -f \"${barcodefile}\" ]\n",
    "        then\n",
    "            echo \"Downloading BAM files for sample ${sample} from server\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "            aws s3 cp s3://cxcr4-pdac/cellranger_7.1.0/GM${i}/possorted_genome_bam.bam $bam_local\n",
    "            aws s3 cp s3://cxcr4-pdac/cellranger_7.1.0/GM${i}/possorted_genome_bam.bam.bai ${bam_local}.bai\n",
    "            samtools view $bam_local | egrep -wo \"CB:Z:.*?UR\" | \\\n",
    "                awk '{print $1}' | awk -F \":\" '{arr[$3] = 1} END {for (key in arr) {print key}}' > $barcodefile\n",
    "        else\n",
    "            echo \"BAM file ${bam_local} already exists; not re-downloading\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "        fi\n",
    "\n",
    "\n",
    "        # Then run the numbat processes here\n",
    "        if [ ! -f \"${pileup_donefile}\" ]\n",
    "        then\n",
    "            echo \"Running Numbat on ${sample}; log at ${logfile}\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "            \n",
    "            # Run on r5.large; took > 2 days and still only 18% of SNPs were processed\n",
    "            # Now rerunning on c5.9xlarge; fingers crossed.\n",
    "\n",
    "            Rscript /home/ubuntu/miniconda3/envs/numbat/lib/R/library/numbat/bin/pileup_and_phase.R \\\n",
    "                --label ${sample} \\\n",
    "                --samples ${sample} \\\n",
    "                --bams ${bam_local} \\\n",
    "                --barcodes ${barcodefile} \\\n",
    "                --outdir ${outdir} \\\n",
    "                --gmap \"${NUMBAT}/Eagle_v2.4.1/tables/genetic_map_hg38_withX.txt.gz\" \\\n",
    "                --eagle \"${CONDA_PREFIX}/bin/eagle\" \\\n",
    "                --snpvcf \"${NUMBAT}/genome1K.phase3.SNP_AF5e2.chr1toX.hg38.vcf\" \\\n",
    "                --paneldir \"${NUMBAT}/1000G_hg38\" \\\n",
    "                --ncores \"${cores}\" 2>&1 | ts '[%Y-%m-%d %H:%M:%S]' \\\n",
    "                    > \"${logfile}\"\n",
    "            \n",
    "            if ! grep -q \"Execution halted\" <(tail -n 5 \"${logfile}\")\n",
    "            then\n",
    "                echo \"Sample ${sample} finished successfully\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "                touch ${pileup_donefile}\n",
    "                rm ${bam_local} ${barcodefile}\n",
    "\n",
    "                # IF the pileup donefile DOES exist then just proceed to downstream Numbat\n",
    "            else\n",
    "                echo \"Sample ${sample}\" finished unsuccessfully | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "            fi\n",
    "        fi\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run this with the `integration` kernel, not `cxcr4`\n",
    "\n",
    "\n",
    "# Make global reference using immune cells\n",
    "\n",
    "\n",
    "library(Seurat)\n",
    "library(tidyverse)\n",
    "library(patchwork)\n",
    "\n",
    "outdir <- '/home/ubuntu/data/cxcr4-pdac/seurat/'\n",
    "message_ <- function(m) {\n",
    "    message(paste(Sys.time(), ': ', m))\n",
    "}\n",
    "\n",
    "obj.list <- list()\n",
    "\n",
    "for (i in seq(18, 40)) {\n",
    "    if (i == 25) next();\n",
    "    if (!(i %in% c(18, 20, 21, 28, 30, 32, 35, 37, 38))) next(); # just the samples with unambiguous T cell clusters based on initial predictions\n",
    "\n",
    "    sample <- paste0('GM', i)\n",
    "    # message_(paste('Reading sample', sample))\n",
    "    rds <- file.path(outdir, paste0(sample, '/', sample, '_cb.rds'))\n",
    "    obj.list[[i]] <- readRDS(rds)\n",
    "    message_(paste(sample, 'has', dim(obj.list[[i]]@meta.data)[1], 'cells'))\n",
    "}\n",
    "obj.list <- obj.list[lengths(obj.list) != 0]  # Reset the index bc we skipped to 18\n",
    "\n",
    "\n",
    "\n",
    "message_('Normalizing and Finding Variable Features for each sample')\n",
    "obj.list <- lapply(X = obj.list, FUN = function(x) {\n",
    "    DefaultAssay(x) <- 'RNA'\n",
    "    x <- NormalizeData(x, assay='RNA')\n",
    "    x <- FindVariableFeatures(x, selection.method = \"vst\", nfeatures = 2000, assay='RNA')\n",
    "})\n",
    "message_('Selecting integration features')\n",
    "features <- SelectIntegrationFeatures(object.list = obj.list, assay=rep('RNA', length(obj.list)))\n",
    "message_('Finding integration anchors')\n",
    "# Credit to Mori for the `smallest_sample` bit. If n_cells < k.score, integration will fail\n",
    "smallest_sample = min(min(sapply(X = obj.list, FUN = ncol)), 101)-1\n",
    "anchors <- FindIntegrationAnchors(object.list = obj.list, anchor.features = features, \n",
    "                                  # reduction='rpca',  # Mori has beef with RPCA so default is CCA\n",
    "                                  dims = 1:smallest_sample,  # critical parameter\n",
    "                                  k.score = smallest_sample, # critical parameter\n",
    "                                  k.anchor = 5,\n",
    "                                  k.filter = 200 # Change to NA if necessary\n",
    "                                  )\n",
    "\n",
    "message_('Actually integrating')\n",
    "combined <- IntegrateData(anchorset = anchors, normalization.method='LogNormalize',\n",
    "                          k.weight = smallest_sample)\n",
    "\n",
    "message_('Post-integration scaling, reduction, and clustering')\n",
    "DefaultAssay(combined) <- \"integrated\"\n",
    "combined <- ScaleData(combined, verbose = FALSE)\n",
    "combined <- RunPCA(combined, npcs = 50, verbose = FALSE)\n",
    "combined <- RunUMAP(combined, reduction = \"pca\", dims = 1:35)\n",
    "combined <- FindNeighbors(combined, reduction = \"pca\", dims = 1:35)\n",
    "combined <- FindClusters(combined, resolution = 0.5)\n",
    "\n",
    "saveRDS(combined, file.path(outdir, 'integrated_data.RDS'))  # NOT all samples, just those with unambiguous T cell clusters\n",
    "# We integrate all samples in a later script\n",
    "\n",
    "# In retrospect, creating this object wasn't *strictly* necessary since\n",
    "# we ended up subsetting out the immune cells based solely on SingleR predictions.\n",
    "# However, it was useful to get confirmation that all the predicted T cells\n",
    "# did indeed cluster together\n",
    "\n",
    "# Took about 3-4h total on r5.4xlarge for 22 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "library(tidyverse)\n",
    "library(patchwork)\n",
    "\n",
    "outdir <- '/home/ubuntu/data/cxcr4-pdac/seurat/'\n",
    "message_ <- function(m) {\n",
    "    message(paste(Sys.time(), ': ', m))\n",
    "}\n",
    "combined <- readRDS(file.path(outdir, 'integrated_data.RDS'))\n",
    "# reference <- readRDS(file.path(outdir, 'reference.RDS'))\n",
    "reference <- subset(combined, celltype_bped_main%in%c('CD4+ T-cells', 'CD8+ T-cells', 'NK cells'))\n",
    "ref_cells <- rownames(reference@meta.data)\n",
    "\n",
    "# New block\n",
    "combined <- ScaleData(combined, verbose = FALSE)\n",
    "combined <- RunPCA(combined, npcs = 30, verbose = FALSE)\n",
    "combined <- RunUMAP(combined, reduction = \"pca\", dims = 1:30)\n",
    "combined <- FindNeighbors(combined, reduction = \"pca\", dims = 1:30)\n",
    "combined <- FindClusters(combined, resolution = 0.5)\n",
    "\n",
    "\n",
    "reference <- subset(combined, celltype_bped_main%in%c('CD4+ T-cells', 'CD8+ T-cells', 'NK cells'))\n",
    "ref_cells <- rownames(reference@meta.data)\n",
    "combined@meta.data[rownames(combined@meta.data) %in% ref_cells, 'Reference'] <- TRUE\n",
    "combined@meta.data$Reference[is.na(combined@meta.data$Reference)] <- 0\n",
    "\n",
    "# Keep only the most high-quality clusters for our global reference\n",
    "# This means removing cells from the reference if they are predicted as T but\n",
    "# make up less than 25% of the cluster\n",
    "good_clust <- combined@meta.data %>%\n",
    "    group_by(seurat_clusters) %>%\n",
    "    summarize(freq = sum(Reference)/n()) %>%\n",
    "    filter(freq > 0.25) %>%\n",
    "    .$seurat_clusters\n",
    "\n",
    "reference <- subset(reference, seurat_clusters %in% good_clust)\n",
    "ref_cells <- rownames(reference@meta.data)\n",
    "saveRDS(reference, file.path(outdir, 'reference.RDS'))\n",
    "\n",
    "p1 <- DimPlot(combined, reduction = \"umap\", group.by = \"celltype_bped_main\", label = TRUE,\n",
    "               repel = TRUE) + theme(legend.position = \"none\")\n",
    "p2 <- DimPlot(combined, reduction = \"umap\", group.by = \"seurat_clusters\", label = TRUE,\n",
    "                repel = TRUE) + theme(legend.position = \"none\")\n",
    "p3 <- DimPlot(combined, reduction = \"umap\", group.by = \"orig.ident\", label = FALSE) + theme(legend.position = \"none\")\n",
    "p4 <- DimPlot(object = combined, cells.highlight = ref_cells, cols.highlight = \"red\", \n",
    "        cols = \"gray\", order = TRUE) + \n",
    "        ggtitle(paste0('Reference (n = ', length(ref_cells), ')')) + \n",
    "        theme(legend.position = \"none\")\n",
    "w <- 4\n",
    "h <- w * 5\n",
    "options(repr.plot.width=w, repr.plot.height=h)\n",
    "print(p1 / p2 / p3 / p4)\n",
    "ggsave(file.path(outdir, 'reference_subset.png'), height=h, width=w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5)\n",
    "DimPlot(combined, reduction = \"umap\", group.by='orig.ident')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Numbat processing\n",
    "\n",
    "Run these using the `numbat` env"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This block is just to collate data because I was processing on separate machines\n",
    "\n",
    "# Run this on the other machines that are doing the pileup in parallel\n",
    "cd /home/ubuntu/data/cxcr4-pdac/numbat/\n",
    "rm -rf input\n",
    "for dir in $(ls .)\n",
    "    do echo $dir\n",
    "    aws s3 cp $dir s3://cxcr4-pdac/numbat/$dir --recursive\n",
    "done\n",
    "\n",
    "# Then run this on the main analysis machine\n",
    "cd /home/ubuntu/data/cxcr4-pdac/numbat/\n",
    "for i in {18..40}\n",
    "do\n",
    "    if [ $i -ne 25 ]\n",
    "    then\n",
    "        aws s3 cp s3://cxcr4-pdac/numbat/ . --recursive\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "conda activate numbat\n",
    "\n",
    "# Took about 1h:10m for GM18 on r5.4xlarge with 16 cores\n",
    "# When I first ran it, I used the 4-machines-in-parallel trick as described above\n",
    "projectdir=\"/home/ubuntu/projects/edsouza-summer2023/cxcr4-pdac\"\n",
    "for i in {18..40}\n",
    "do\n",
    "    if [[  $i -ne 25 ]] \n",
    "    then\n",
    "        sample=\"GM${i}\"\n",
    "        outdir=\"${projectdir}/data/numbat/${sample}/numbat_downstream\"\n",
    "        logfile=\"${outdir}/numbat_log.txt\"\n",
    "        donefile=\"${outdir}/done.checkpoint\"\n",
    "\n",
    "        mkdir -p ${outdir}\n",
    "\n",
    "        if [ ! -f \"${donefile}\" ]\n",
    "        then\n",
    "            echo \"Starting sample ${sample}. Log at ${logfile}\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "            Rscript \"${projectdir}/05b_Numbat.R\" ${sample} 2>&1 | ts '[%Y-%m-%d %H:%M:%S]' > \"${logfile}\"\n",
    "\n",
    "            if ! grep -q \"Execution halted\" <(tail -n 5 \"${logfile}\")\n",
    "            then\n",
    "                echo \"Sample ${sample} finished successfully\"  | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "                touch \"${donefile}\"\n",
    "            else\n",
    "                echo \"Sample ${sample} finished unsuccessfully\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "            fi\n",
    "        else\n",
    "            echo \"Sample ${sample} already finished; skipping\" | ts '[%Y-%m-%d %H:%M:%S]'\n",
    "        fi\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Use the `numbat` env for this part\n",
    "\n",
    "library(numbat)\n",
    "library(dplyr)\n",
    "library(Seurat)\n",
    "library(ggplot2)\n",
    "library(stringr)\n",
    "library(patchwork)\n",
    "library(gifski)\n",
    "\n",
    "'%notin%' <- Negate('%in%')\n",
    "message_ <- function(m) {\n",
    "    message(paste(Sys.time(), ': ', m))\n",
    "}\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Read-in numbat output\n",
    "produce_seurat <- function(pat) {\n",
    "    projectdir <- file.path('/home/ubuntu/data/cxcr4-pdac')\n",
    "    seu_file <- file.path(projectdir, 'seurat', pat, paste0(pat, '_cb.rds'))\n",
    "    allele_pileup <- file.path(projectdir, 'numbat', pat, paste0(pat, '_allele_counts.tsv.gz')) # From pileup\n",
    "    outdir <- file.path(projectdir, 'numbat', pat, 'numbat_downstream')  # From numbat R script\n",
    "    gif_dir <- file.path(outdir, 'create_gif')\n",
    "\n",
    "    nb = Numbat$new(out_dir = outdir)\n",
    "    seu <- readRDS(seu_file)\n",
    "\n",
    "    # Single-cell CNV calls\n",
    "    cnv_calls<- nb$joint_post %>% select(cell, CHROM, seg, cnv_state, p_cnv, p_cnv_x, p_cnv_y)\n",
    "\n",
    "    # Clone info\n",
    "    clones<-dim(table(nb$clone_post$clone_opt))\n",
    "    clone_info<-nb$clone_post\n",
    "    seu$cell<-colnames(seu)\n",
    "    seu@meta.data<-left_join(seu@meta.data,clone_info,by='cell')\n",
    "    rownames(seu@meta.data)<-colnames(seu)\n",
    "    return(list('seurat'=seu, 'gif_dir'=gif_dir))\n",
    "}\n",
    "\n",
    "filter_numbat_threshold <- function(seu, outdir,\n",
    "                                    thresholds=seq(0,1,0.01), \n",
    "                                    min_prevalence = 10, \n",
    "                                    create_gif = FALSE, delay=0.3,\n",
    "                                    return_seurat_object = FALSE) {\n",
    "\n",
    "    if (return_seurat_object) {\n",
    "        stopifnot('To return seurat object, `thresholds` must be a scalar value' = length(thresholds) == 1)\n",
    "        stopifnot('To return Seurat object, you `create_gif` must be FALSE' = !create_gif)\n",
    "    }\n",
    "\n",
    "    samplename <- seu@meta.data$orig.ident %>% unique()\n",
    "    stopifnot('Seurat object must only have a single `orig.ident`' = length(samplename) == 1)\n",
    "\n",
    "    # First, pre-compute prevalence graph for p3\n",
    "    prevalence <- list()\n",
    "    ct = 1\n",
    "\n",
    "    message_(paste('Computing thresholds for', samplename))\n",
    "    for (thresh in seq(0,1,0.01)) {  # This remains hard-coded\n",
    "        seu$selected <- seu$p_cnv_y > thresh\n",
    "        # Cleanup\n",
    "        prev_df <- seu@meta.data %>% \n",
    "                            group_by(seurat_clusters) %>% \n",
    "                            summarize(prevalence = 100 * sum(selected)/n()) %>%\n",
    "                            filter(prevalence > min_prevalence) %>%  # 10% prevalence threshold\n",
    "                            mutate(threshold = thresh)\n",
    "        prevalence[[ct]] <- prev_df; ct <- ct + 1\n",
    "        allowed_clusters <- prev_df$seurat_clusters\n",
    "        seu$selected_filtered <- seu$selected & (seu$seurat_clusters %in% allowed_clusters)\n",
    "    }\n",
    "    prevalence <- dplyr::bind_rows(prevalence)\n",
    "\n",
    "\n",
    "    message_(paste('Creating images for', samplename))\n",
    "    pic_ct <- 0\n",
    "    for (thresh in thresholds) {\n",
    "        seu$selected <- seu$p_cnv_y > thresh\n",
    "        # Cleanup\n",
    "        prev_df <- seu@meta.data %>% \n",
    "                            group_by(seurat_clusters) %>% \n",
    "                            summarize(prevalence = 100 * sum(selected)/n()) %>%\n",
    "                            filter(prevalence > min_prevalence) %>%\n",
    "                            mutate(threshold=thresh)\n",
    "        allowed_clusters <- prev_df$seurat_clusters\n",
    "        seu$selected_filtered <- seu$selected & (seu$seurat_clusters %in% allowed_clusters)\n",
    "\n",
    "        suppressMessages(suppressWarnings({\n",
    "            p1 <- DimPlot(seu, group.by='selected', order = T) +\n",
    "            scale_color_manual(values=c('FALSE'='grey', 'TRUE'='red')) +\n",
    "            ggtitle(paste0(samplename, \n",
    "                          ' Tumor vs normal probability (allele)\\nThreshold = ', \n",
    "                          thresh))\n",
    "\n",
    "            p2 <- DimPlot(seu, group.by='selected_filtered', order = T) +\n",
    "                scale_color_manual(values=c('FALSE'='grey', 'TRUE'='red')) +\n",
    "                ggtitle(paste0(samplename, \n",
    "                               ' Tumor vs normal probability (allele)\\nThreshold = ', \n",
    "                               thresh, '; FILTERED'))\n",
    "\n",
    "            p3 <- ggplot(prevalence, aes(threshold, prevalence, color=seurat_clusters)) + \n",
    "                    geom_line() + \n",
    "                    geom_vline(xintercept=thresh, color='red', linetype='dashed') +\n",
    "                    geom_hline(yintercept=min_prevalence, color='black', linetype='dashed') +\n",
    "                    xlim(0,1) + ylim(0,100) + \n",
    "                    scale_x_continuous(expand = c(0, 0), limits = c(0, NA)) + \n",
    "                    scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) +\n",
    "                    theme_classic() + theme(legend.position = \"none\") +\n",
    "                    ylab('% of malignant cells in cluster') +\n",
    "                    ggtitle(paste0(samplename, \n",
    "                                   ' Malignant prevalence per cluster (FILTERED), threshold = ', \n",
    "                                   thresh))\n",
    "        }))\n",
    "\n",
    "        # Produce plot files\n",
    "        if (!dir.exists(outdir)) {\n",
    "            dir.create(outdir, recursive = T)\n",
    "        }\n",
    "        outfile <- file.path(outdir, paste0(samplename, '_numbat_thresh_', \n",
    "                                            str_pad(thresh*100, 2, pad='0'),\n",
    "                                            '_min_prev_', min_prevalence,\n",
    "                                            '.png'))\n",
    "        ggsave(outfile, ((p1 + p2) / p3),\n",
    "              width = 12, height = 10, dpi = 300, \n",
    "              units = \"in\", device='png') %>% suppressMessages() %>% suppressWarnings()\n",
    "        \n",
    "        if (pic_ct %% 10 == 0) {\n",
    "            message_(paste0('Produced plot for ', outfile))\n",
    "        }\n",
    "\n",
    "\n",
    "        # Will only run if `thresholds` is a single value and we're not creating a gif\n",
    "        if (return_seurat_object) {\n",
    "            message_(paste0('Returning Seurat object for ', \n",
    "                             samplename, ' threshold ', thresh, \n",
    "                             ' and min prevalence ', min_prevalence,'%.'))\n",
    "            return(seu)\n",
    "        }\n",
    "        pic_ct <- pic_ct + 1\n",
    "    }\n",
    "    \n",
    "\n",
    "    if (create_gif) {\n",
    "        gif_path <- file.path(outdir, paste0(samplename, '_numbat_thresholds.gif'))\n",
    "        png_files <- file.path(outdir, paste0(samplename, '_numbat_thresh_', \n",
    "                                             str_pad(thresholds*100, 2, pad='0'),\n",
    "                                            '_min_prev_', min_prevalence,\n",
    "                                            '.png'))\n",
    "        message_(paste('Creating GIF for sample', samplename))\n",
    "        gifski::gifski(png_files, gif_path, delay=delay)\n",
    "        message_(paste('Created GIF at', gif_path))\n",
    "        file.remove(png_files)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Now, I just create gifs to help select clusters within each sample that \n",
    "# have the highest prevalence of malignant cells as predicted by Numbat, \n",
    "# while filtering out clusters with low signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM18')\n",
    "# Run this cell multiple times with various values of \n",
    "# `thresholds` and `min_prevalence` until you get good separation\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "# # Finally, after you've tweaked the results and decided on an optimum\n",
    "# # This will add the new boolean columns `selected` and `selected_filtered`\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.43,\n",
    "                                min_prevalence=30,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)\n",
    "# # Now you're free to saveRDS and do downstream analysis on malignant cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM19')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.10,\n",
    "                                min_prevalence=75,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM20')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.12,\n",
    "                                min_prevalence=30,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM21')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.30,\n",
    "                                min_prevalence=75,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM23')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.15, \n",
    "                                min_prevalence=75,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM26')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.15, \n",
    "                                min_prevalence=85,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM27')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.05, \n",
    "                                min_prevalence=90,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM28')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.15, \n",
    "                                min_prevalence=90,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM30')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.20, \n",
    "                                min_prevalence=85, # ???\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM31')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.05, \n",
    "                                min_prevalence=90,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM32')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.1, \n",
    "                                min_prevalence=90,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM33')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.45, \n",
    "                                min_prevalence=60,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM37')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=30,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.15, \n",
    "                                min_prevalence=80,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM38')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=10,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.05, \n",
    "                                min_prevalence=50,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM39')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=20,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.15, \n",
    "                                min_prevalence=90,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seu <- produce_seurat('GM40')\n",
    "\n",
    "# filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "#                         thresholds=seq(0,1,0.01),\n",
    "#                         min_prevalence=10,\n",
    "#                         create_gif=T, \n",
    "#                         delay=0.3  # Only matters if `create_gif` is TRUE\n",
    "#                         )\n",
    "\n",
    "seu <- filter_numbat_threshold(seu[['seurat']], outdir=seu[['gif_dir']],\n",
    "                                thresholds=0.20, \n",
    "                                min_prevalence=90,\n",
    "                                create_gif=F,\n",
    "                                return_seurat_object=T) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
